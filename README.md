# BCS_Harry_Potter_Kritin
I have first created the environment in which I have defined the functions based on action of harry and death eater.
I have created a function for choosing the action of harry based o the value of epsilon
Then I have trained the table and eventually over time got a success rate of 58%
I have also plotted the moving avg of the rewards and the success array in which 1 for success and 0 for failiure
I also tried this question with a DQN system (didnt work out well lol)
I think I was not able to save the data for the weights of the DQN using pickle but couldnt find any reason as to why.
Used the same environment for the DQN and changed the weights of the network using the loss function
Also I kept a target network to stabilise my target for a while after which I updated it to the policy
I have also plotted the moving averages here as well
Visualised both using pygame
